# text-attacks
Code to attack NLP models using perturbations (for a course project on ML in Adversarial Settings)
